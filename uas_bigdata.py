# -*- coding: utf-8 -*-
"""UAS BIGDATA FIX.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M7Qry31Oygz4117RVcQ56G983VDIfX--
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pyspark

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import pyspark.sql.functions as F
from pyspark.sql.types import IntegerType

# Inisialisasi sesi Spark
spark = SparkSession.builder.appName("KrisisEkonomiAfrika").getOrCreate()

# Mengubah peringatan menjadi tidak tercetak
spark.sparkContext.setLogLevel("ERROR")

# Mengatur opsi tampilan
spark.conf.set("spark.sql.repl.eagerEval.enabled", True)

# Membaca file CSV
df = spark.read.format("csv").option("header", True).load("/content/drive/MyDrive/BIGDATA/african_crises.csv")

#membaca data
df.printSchema()

# Menampilkan 10 baris pertama
df.show(10)

#menampilkan kolom tertentu (negara merdeka)
from pyspark.sql.functions import col

merdeka = df.filter(col('independence') == 1).select('country', 'year', 'banking_crisis')

merdeka.show(20)

# Melihat apakah ada data tiap tahun
from pyspark.sql.functions import count
from pyspark.sql import functions as F

# mengelompokkan menurut negara dan pivot pada tahun
cross_tab = df.groupBy('country').pivot('year').agg(count('*')).fillna(0)

# Menampilkan tabulasi silang
cross_tab.show()

# Berapa kali negara-negara tersebut mengalami krisis mata uang?
from pyspark.sql import functions as F

# mengelompokkan berdasarkan negara dan hitung jumlah krisis mata uang
currency_crises = df.groupBy('country').agg(F.sum('currency_crises').alias('total_currency_crises')).sort('total_currency_crises', ascending=False)

currency_crises.show()

# Berapa kali negara-negara tersebut mengalami inflasi
from pyspark.sql import functions as F

# mengelompokkan berdasarkan negara dan hitung jumlah krisis inflasi
inflation_crises = df.groupBy('country').agg(F.sum('inflation_crises').alias('total_inflation_crises')).sort('total_inflation_crises', ascending=False)

inflation_crises.show()

#menampilkan tingkat IHK (rasio hutang tiap negara)
# Convert the PySpark DataFrame to a Pandas DataFrame
df_pandas = df.select('year', 'gdp_weighted_default', 'country').toPandas()

# Memplot diagram garis menggunakan Matplotlib dan Panda
plt.figure(figsize=(8, 5))
for country in df_pandas['country'].unique():
    data = df_pandas[df_pandas['country'] == country]
    plt.plot(data['year'], data['gdp_weighted_default'], label=country)

plt.xlabel('Year')
plt.ylabel('Debt Ratio')
plt.legend()
plt.show()

!pip install plotly

import plotly.express as px

# Mengurutkan tahun secara menaik
sorted_years = sorted(pandas_df['year'].unique())

# Memplot nilai tukar menggunakan Plotly dan mengurutkan tahun
fig = px.line(pandas_df, x='year', y='exch_usd', color='country',
              category_orders={'year': sorted_years})

# Menampilkan plot
fig.show()

#menampilkan Visualisasi berbagai jenis krisis
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns

# Membuat SparkSession
spark = SparkSession.builder.appName("CrisisVisualization").getOrCreate()

# Menentukan jalur ke file data
filePath = "/content/drive/MyDrive/BIGDATA/african_crises.csv"

# Muat data ke dalam DataFrame
df = spark.read.format("csv").option("header", "true").load(filePath)

# Menentukan kolom untuk berbagai jenis krisis
cols = ['currency_crises', 'inflation_crises', 'banking_crisis', 'systemic_crisis']

# Merencanakan jumlah krisis untuk setiap negara
fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(18, 12), dpi=60)
axes = axes.flatten()

for i, ax in zip(cols, axes):
    sns.countplot(y='country', ax=ax, data=df.toPandas(), hue=i, palette='bright')

plt.tight_layout()
plt.show()

"""**PROGRAM PYSPARK MENGGUNAKAN MACHINE LEARNING DENGAN MEMPREDIKSI NEGARA MANA YANG PALING MENGALAMI KRISIS EKONOMI DAN NEGARA MANA YANG PALING MAKMUR**"""

# Import library yang diperlukan
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator

# Inisialisasi SparkSession
spark = SparkSession.builder.appName("EconomicAnalysis").getOrCreate()

# Baca dataset
dataset = spark.read.csv("/content/drive/MyDrive/BIGDATA/african_crises.csv", header=True, inferSchema=True)

# Preprocessing data
# Anggap fitur yang relevan untuk analisis adalah exch_usd, inflation_annual_cpi, dan banking_crisis
assembler = VectorAssembler(inputCols=["exch_usd", "inflation_annual_cpi"], outputCol="features")
data = assembler.transform(dataset)

# Menentukan jumlah cluster
kmeans = KMeans(k=5, seed=1)

# Melatih model KMeans
model = kmeans.fit(data)

# Melakukan prediksi
predictions = model.transform(data)

# Menampilkan negara dengan nilai prediksi yang paling rendah (paling kritis)
most_crisis_country = predictions.orderBy("prediction").select("country").first()

# Menampilkan negara dengan nilai prediksi yang paling tinggi (paling makmur)
most_prosperous_country = predictions.orderBy(predictions.prediction.desc()).select("country").first()

# Mengukur akurasi model menggunakan evaluator clustering
evaluator = ClusteringEvaluator()
silhouette_score = evaluator.evaluate(predictions)

# Menampilkan hasil
print("Negara yang paling mengalami krisis ekonomi: ", most_crisis_country[0])
print("Negara yang paling makmur: ", most_prosperous_country[0])
print("Silhouette Score: ", silhouette_score)

# Menghentikan SparkSession
spark.stop()

